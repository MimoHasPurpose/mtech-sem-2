{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6151db54-6d55-438b-932b-0b995f809b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba204df2-4699-4194-8f65-d6085ea3b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys,  torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset, TensorDataset\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21a1bab0-d0af-4c82-aebd-db123b69ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_path=\"dataset/poems-100.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a36355c6-cf22-4212-876f-00982b98f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize:\n",
    "text = \"\\n\".join(pd.read_csv(csv_path)[\"text\"].astype(str)).lower()\n",
    "tokens = text.split()\n",
    "vocab = sorted(set(tokens))\n",
    "w2i = {w:i for i,w in enumerate(vocab)}\n",
    "i2w = {i:w for w,i in w2i.items()}\n",
    "encoded = [w2i[w] for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4d3e491-3316-467b-8e80-645b74687ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence\n",
    "seq_len = 6\n",
    "X, Y = [], []\n",
    "for i in range(len(encoded)-seq_len):\n",
    "    X.append(encoded[i:i+seq_len])\n",
    "    Y.append(encoded[i+seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36ec76ce-e294-400b-a972-5fa86c231701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "\n",
    "X, Y = torch.tensor(X), torch.tensor(Y)\n",
    "loader = DataLoader(TensorDataset(X,Y), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18388b87-cdde-4b34-ae03-77660b367508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model:\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab,64)\n",
    "        self.rnn = nn.RNN(64,128,batch_first=True)\n",
    "        self.fc = nn.Linear(128,vocab)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.emb(x)\n",
    "        o,_ = self.rnn(x)\n",
    "        return self.fc(o[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "569e446e-6c5d-486e-819f-4e61d801535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(len(vocab))\n",
    "opt = torch.optim.Adam(model.parameters(),lr=0.003)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82d6d476-cb09-41eb-9e8d-94fb0ba29583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:06<00:55,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 6.577138866212358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:12<00:49,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 5.461843350880513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:18<00:43,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 loss 4.224829150665006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:24<00:37,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 loss 3.1482478250661456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:31<00:31,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 loss 2.3660343245423627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:37<00:24,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 loss 1.8267150272989952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:43<00:18,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 loss 1.433049115218598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:49<00:12,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 loss 1.1666541586101131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:55<00:06,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 loss 0.9708469511620594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:02<00:00,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 loss 0.8266851588563191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for epoch in tqdm.tqdm(range(10)):\n",
    "    total=0\n",
    "    for xb,yb in loader:\n",
    "        opt.zero_grad()\n",
    "        loss = loss_fn(model(xb),yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total+=loss.item()\n",
    "    print(\"epoch\",epoch,\"loss\",total/len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9111c4f4-1813-43e3-b76b-5e9f4a43dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  poem generation:\n",
    "def generate(seed=\"love is\",words=40):\n",
    "    model.eval()\n",
    "    toks = seed.lower().split()\n",
    "    idxs = [w2i.get(w,0) for w in toks]\n",
    "\n",
    "    for _ in range(words):\n",
    "        x = torch.tensor([idxs[-seq_len:]])\n",
    "        with torch.no_grad():\n",
    "            p = torch.softmax(model(x),dim=-1)\n",
    "        nxt = torch.multinomial(p,1).item()\n",
    "        idxs.append(nxt)\n",
    "\n",
    "    return \" \".join(i2w[i] for i in idxs)\n",
    "\n",
    "print(\"\\nGenerated poem:\\n\")\n",
    "print(generate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ad5d1-b4cd-480f-b88a-5f65c22cee42",
   "metadata": {},
   "source": [
    "Extra:\n",
    "- save model weights, and model\n",
    "- train on a larger dataset\n",
    "- reduce the size of model\n",
    "- show how data passes to model layers\n",
    "- compare poem outputs with different training levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4ad36-7e32-4f35-8a20-e3e79ddd00d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e643e-cb53-4e17-a626-ba8d3f46b41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec93be-2a84-447e-a667-982bd11f6aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9428235,
     "sourceId": 14751736,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
